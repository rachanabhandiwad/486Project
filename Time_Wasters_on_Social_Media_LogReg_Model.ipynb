{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1231560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niki/opt/anaconda3/lib/python3.9/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Downloading kagglehub-0.3.11-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c7ff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/muhammadroshaanriaz/time-wasters-on-social-media?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36.0k/36.0k [00:00<00:00, 278kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Data source import complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "muhammadroshaanriaz_time_wasters_on_social_media_path = kagglehub.dataset_download('muhammadroshaanriaz/time-wasters-on-social-media')\n",
    "\n",
    "print('Data source import complete.')\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0992e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/root/.cache/kagglehub/datasets/muhammadroshaanriaz/time-wasters-on-social-media/versions/1/Time-Wasters on Social Media.csv')\n",
    "print('### first 5 lines ###','\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6823420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper func\n",
    "def convertHours(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        if isinstance(value, str):\n",
    "            numbers = [float(num) for num in value.split() if num.replace('.', '', 1).isdigit()]\n",
    "            if numbers:\n",
    "                return sum(numbers) / len(numbers)\n",
    "        return 0\n",
    "\n",
    "def preprocess(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.dropna()\n",
    "    df['num_platforms'] = df['7. What social media platforms do you commonly use?'].apply(lambda x: len(str(x).split(',')))\n",
    "    df['target'] = df['8. What is the average time you spend on social media every day?'].apply(lambda x: 1 if convertHours(x) > 3 else 0)\n",
    "\n",
    "    X = df[['num_platforms', \n",
    "            '9. How often do you find yourself using Social media without a specific purpose?', \n",
    "            '12. On a scale of 1 to 5, how easily distracted are you?', \n",
    "            '14. Do you find it difficult to concentrate on things?']].values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # split training + validation & testing (85/15)\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "    # split: training & validation (85/15 from 85, 0.1765 * 85% ≈ 15% of total)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66704c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(filepath, epochs=50, batch_size=32, learning_rate=0.01):\n",
    "    # preprocess data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess(filepath)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = LogisticRegressionModel(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    torch.save((X_test, y_test), './models/test_data.pth')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "\n",
    "    torch.save(model.state_dict(), './models/productivity_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ebba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(filepath):\n",
    "    model = LogisticRegressionModel(input_dim=4)\n",
    "    model.load_state_dict(torch.load('./models/productivity_model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    X_test, y_test = torch.load('./models/test_data.pth')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "\n",
    "        # baseline value predictions\n",
    "        baseline_prediction_productivity_loss = 4.80 \n",
    "        baseline_prediction_addiction_level = 7.16\n",
    "\n",
    "        # use the baseline for MSE comparison\n",
    "        baseline_productivity_loss = np.full_like(y_test.numpy(), baseline_prediction_productivity_loss)\n",
    "        baseline_addiction_level = np.full_like(y_test.numpy(), baseline_prediction_addiction_level)\n",
    "\n",
    "        # calculate MSE for comparison to baseline\n",
    "        mse_productivity_loss = mean_squared_error(y_test.numpy(), baseline_productivity_loss)\n",
    "        mse_addiction_level = mean_squared_error(y_test.numpy(), baseline_addiction_level)\n",
    "\n",
    "        # calculate MSE for model's predictions\n",
    "        mse_model = mean_squared_error(y_test.numpy(), outputs.numpy())\n",
    "\n",
    "        # accuracy\n",
    "        accuracy = (predictions.eq(y_test).sum() / y_test.shape[0]).item()\n",
    "\n",
    "        # precision\n",
    "        precision = precision_score(y_test.numpy(), predictions.numpy())\n",
    "\n",
    "        # recall\n",
    "        recall = recall_score(y_test.numpy(), predictions.numpy())\n",
    "\n",
    "        # F1-score\n",
    "        f1 = f1_score(y_test.numpy(), predictions.numpy())\n",
    "        \n",
    "        print(f'Mean Squared Error (Model): {mse_model:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, y_test_numpy = preprocess(df)\n",
    "model = trainModel(X_train, X_val, y_train, y_val, input_dim=X_train.shape[1])\n",
    "testModel(model, X_test, y_test, y_test_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
