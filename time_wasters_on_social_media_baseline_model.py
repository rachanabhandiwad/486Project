# -*- coding: utf-8 -*-
"""Time Wasters on Social Media Baseline Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XqU5T3IEfUdPCKWV6wcyY9eNI4FLA25E
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
muhammadroshaanriaz_time_wasters_on_social_media_path = kagglehub.dataset_download('muhammadroshaanriaz/time-wasters-on-social-media')

print('Data source import complete.')

"""## <b><div style='padding:30px;background-color:#001BC7;color:white;border-radius:80px;font-size:150%;text-align: center'>Time Wasters on Social Media</div></b>"""

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>1  |  About Dataset</div></b>

**Time-Wasters on Social Media Dataset**

**Overview**

The "Time-Wasters on Social Media" dataset offers a detailed look into user behavior and engagement with social media platforms. It captures various attributes that can help analyze the impact of social media on users' time and productivity. This dataset is valuable for researchers, marketers, and social scientists aiming to understand the nuances of social media consumption.

This dataset was generated using synthetic data techniques with the help of NumPy and pandas. The data is artificially created to simulate real-world social media usage patterns for research and analysis purposes.**

## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>2  |  Importing Libraries</div></b>
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.offline import iplot
from plotly.subplots import make_subplots

import warnings
warnings.filterwarnings('ignore')

"""## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>3  |  Downloading Dataset</div></b>"""

df = pd.read_csv('/root/.cache/kagglehub/datasets/muhammadroshaanriaz/time-wasters-on-social-media/versions/1/Time-Wasters on Social Media.csv')

# Check Dataset

print('### first 5 lines ###','\n')
df.head()

"""## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>4  |  Inspecting and Cleaning Dataframe Structure</div></b>"""

# Dataframe summary

def summary(df):
    print(f'data shape: {df.shape}')
    summ = pd.DataFrame(df.dtypes, columns=['Data Type'])
    summ['Missing#'] = df.isna().sum()
    summ['Missing%'] = (df.isna().sum())/len(df)
    summ['Dups'] = df.duplicated().sum()
    summ['Uniques'] = df.nunique().values
    summ['Count'] = df.count().values
    desc = pd.DataFrame(df.describe(include='all').transpose())
    summ['Min'] = desc['min'].values
    summ['Max'] = desc['max'].values
    summ['Average'] = desc['mean'].values
    summ['Standard Deviation'] = desc['std'].values
    summ['First Value'] = df.loc[0].values
    summ['Second Value'] = df.loc[1].values
    summ['Third Value'] = df.loc[2].values

    display(summ)

summary(df)

#Correct country name in Dataset
df.replace({'Barzil':'Brazil'}, regex=True,  inplace=True)

"""## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>5  |  EDA</div></b>"""

def grab_col_names(dataframe, cat_th=10, car_th=20):

    # cat_cols, cat_but_car
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == "O"]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f'cat_cols: {len(cat_cols)}')
    print(f'num_cols: {len(num_cols)}')
    print(f'cat_but_car: {len(cat_but_car)}')
    print(f'num_but_cat: {len(num_but_cat)}')

    return cat_cols, num_cols, cat_but_car


cat_cols, num_cols, cat_but_car = grab_col_names(df)

cols_cat = ['Gender',  'Location', 'Profession', 'Demographics', 'Platform',
          'Video Category', 'Frequency', 'Watch Reason', 'DeviceType', 'OS',
          'Watch Time', 'CurrentActivity', 'ConnectionType', 'Importance Score',
          'ProductivityLoss', 'Satisfaction', 'Self Control', 'Addiction Level']

def cat_summary(dataframe, col_name, plot=False):
    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                        "Ratio": 100 * dataframe[col_name].value_counts() / len(dataframe)}))

    if plot:
        fig, axs = plt.subplots(1, 2, figsize=(12, 6))
        plt.subplot(1, 2, 1)
        sns.countplot(x=dataframe[col_name], data=dataframe, palette = 'Set1')
        plt.title("Frequency of " + col_name)
        plt.xticks(rotation=90)

        plt.subplot(1, 2, 2)
        values = dataframe[col_name].value_counts()
        plt.pie(x=values, labels=values.index, autopct=lambda p: '{:.2f}% ({:.0f})'.format(p, p/100 * sum(values)))
        hole = plt.Circle((0, 0), 0.40, facecolor='white')
        plt.gcf().gca().add_artist(hole)
        plt.title("Frequency of " + col_name)
        plt.legend(labels=['{} - {:.2f}%'.format(index, value/sum(values)*100) for index, value in zip(values.index, values)],
                   loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=1)
        plt.show(block=True)

for col in cols_cat:
    cat_summary(df, col, True)

def num_summary(dataframe, numerical_col, plot=False):

    if plot:
            fig, axs = plt.subplots(1, 2, figsize=(10, 4))
            plt.subplot(1, 2, 1)
            dataframe[numerical_col].hist(bins=50, color="#f25ed0")
            plt.xlabel(numerical_col)
            plt.title(numerical_col)

            plt.subplot(1, 2, 2)
            sns.boxplot(y=numerical_col, data=dataframe, color="#f25ed0")
            plt.title("Frequency of " + numerical_col)
            plt.xticks(rotation=90)

            plt.show(block=True)

            print("______________________________________________________\n")

for col in num_cols:
    print(col)
    num_summary(df, col, plot=True)

cols = ['Age', 'Income', 'Total Time Spent', 'Number of Sessions',
        'Video Length', 'Engagement', 'Time Spent On Video',
        'Number of Videos Watched', 'Scroll Rate']

colors = ["#8c0404","#f25ed0","#21618C","#16A085","#34495E",
          "#C70039", "#FF5733", "#FFC300", "#DAF7A6", "#B3B6B7",
          '#6495ED', '#40E0D0', '#9FE2BF', '#CCCCFF']

# Highest Location according to Average of Features

for i in cols:

    if i == 'Age':
        df_top = df.groupby(['Location'])[['Age']].mean()
        df_top = df_top.sort_values(by=("Age"), ascending=False).head(14)

        iplot(px.bar(df_top[:14],
             text_auto = True,
             color = df_top[:14].index,
             color_discrete_sequence = colors,
             labels=dict(index="Count Names",value=""),
             title = 'Highest Location according to Average of Age'
            ))

    else:

        df_top = df.groupby(['Location'])[[i]].mean()
        df_top = df_top.sort_values(by=[i], ascending=False).head(14)

        iplot(px.bar(df_top[:14],
             text_auto = True,
             color = df_top[:14].index,
             color_discrete_sequence = colors,
             labels=dict(index="Count Names",value=""),
             title = 'Highest Location according to Average of ' +i
             ))

cols_cat = ['Gender', 'Location', 'Profession', 'Demographics', 'Platform',
            'Video Category', 'Frequency', 'Watch Reason', 'DeviceType', 'OS',
            'Watch Time', 'CurrentActivity', 'ConnectionType', 'Debt', 'Owns Property',
            'Importance Score', 'Satisfaction', 'Self Control', 'Addiction Level']

# Top Features by ProductivityLoss
for i in cols_cat:

    if i == 'Gender':
        fig, ax = plt.subplots(figsize=(12, 5))
        df_prof = df.groupby(['Gender'])[['ProductivityLoss']].mean()
        df_prof = df_prof.sort_values("ProductivityLoss", axis = 0, ascending = False)
        df_prof.reset_index(level=0, inplace=True)
        sns.barplot(x = 'Gender', y = 'ProductivityLoss', data = df_prof,
                   palette = colors)
        ax.bar_label(ax.containers[0], fmt='%0.2f', rotation = 0, fontsize = 12)
        plt.title("Top Gender by Productivity Loss", fontsize = 18)
        plt.show()

    else:

        fig, ax = plt.subplots(figsize=(12, 5))
        df_prof = df.groupby([i])[['ProductivityLoss']].mean()
        df_prof = df_prof.sort_values("ProductivityLoss", axis = 0, ascending = False)
        df_prof.reset_index(level=0, inplace=True)
        sns.barplot(x = i, y = 'ProductivityLoss', data = df_prof,
                   palette = colors)
        ax.bar_label(ax.containers[0], fmt='%0.2f', rotation = 0, fontsize = 12)
        plt.title("Top " + i + " by Productivity Loss", fontsize = 18)
        plt.show()

# Choropleth
df_prod = df.groupby(['Location'])[['ProductivityLoss']].mean()
df_prod.reset_index(level=0, inplace=True)

fig = px.choropleth(df, locations='Location', color = 'ProductivityLoss', locationmode='country names', title = f'Productivity Loss - Average by Location',color_continuous_scale='viridis_r')
fig.show()

df_prod

from sklearn.metrics import mean_squared_error

# Drop rows with missing values for both target columns
df = df.dropna(subset=['ProductivityLoss', 'Addiction Level'])

# Calculate targets
df['productivity_loss'] = 10 - df['ProductivityLoss']

# Baseline prediction: always predict the mean
baseline_prod = df['productivity_loss'].mean()
baseline_addict = df['Addiction Level'].mean()

# Create prediction columns
df['baseline_prod_pred'] = baseline_prod
df['baseline_addict_pred'] = baseline_addict

# Evaluate baseline using MSE
mse_prod = mean_squared_error(df['productivity_loss'], df['baseline_prod_pred'])
mse_addict = mean_squared_error(df['Addiction Level'], df['baseline_addict_pred'])

# Display results
print(f" Baseline Mean Productivity Loss: {baseline_prod:.2f}")
print(f" Productivity Loss MSE: {mse_prod:.4f}")
print(f" Baseline Mean Addiction Level: {baseline_addict:.2f}")
print(f" Addiction Level MSE: {mse_addict:.4f}")

"""## <b><div style='padding:15px;background-color:#001BC7;color:white;border-radius:40px;font-size:110%;text-align: center'>If you liked it, please upvote. Thank you very much.</div></b>"""